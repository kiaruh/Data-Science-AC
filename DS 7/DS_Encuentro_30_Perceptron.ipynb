{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "En este notebook vamos a construir la unidad básica de las redes neuronales, el Perceptrón. Tiene dos partes:\n",
    "1. **Perceptrón a mano**: primero, vamos a estudiar la función sigmoide y la entropía categórica para un caso sencillo, unidimensional. Vamos a encontrar el mínimo de la función de costo haciendo una exploración exhaustiva del espacio de parámetros, simil GridSearch. Podríamos también hacer la parte de gradiente descendiente, pero excede el alcance de lo que queremos presentar en el curso, y además para eso están las librerías como Keras. De todas formas, si alguien se anima, puede intentarlo y lo ayudamos con algunas pistas.\n",
    "2. **Perceptrón con Keras**: luego, vamos a entrenar un Perceptrón con Keras sobre el mismo dataset. Vamos a usarlo como excusa para presentar las principales características de la librería.\n",
    "3. **Perceptrón 2D**: vamos a entrenar un Perceptrón con Keras sobre un dataset ficticio. Exploramos cómo son las fronteras en 2D. Limitaciones del Perceptrón. Como probablemente no alcance el tiempo en esta clase, esta sección también será el comienzo del siguiente notebook.\n",
    "\n",
    "## 1. Perceptrón a mano\n",
    "\n",
    "El objetivo es ajustar un Perceptrón a los datos del Challenger. Recuerden estos datos tienen un solo feature, la temperatura. ¿Cuántos parámetros tendrá el Perceptrón?\n",
    "\n",
    "1. Escribir una función que, dado un vector x y dos parámetros w0 y w1, calcula la función sigmoide. Hacer un plot para algunos parámetros, tratando de obtener los gráficos de la presentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x,w0, w1):\n",
    "    '''Equivalente a perceptron con funcion de activacion sigmoide'''\n",
    "    z = COMPLETAR # z como combinacion lineal de x, w0 y w1\n",
    "    y = COMPLETAR # usar lo que dio en z\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,500)\n",
    "\n",
    "y = sigmoid_function(x, 0,1)\n",
    "plt.plot(x,sigmoid_function(x, 0,1), label = 'w0 = 0, w1 = 1')\n",
    "plt.plot(x,sigmoid_function(x, 0,-1), label = 'w0 = 0, w1 = -1')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escribir una función que, dado la etiqueta de una instancia `y` y una predicción `y_pred`, calcula la función de perdida *entropía cruzada*. Hacer un plot para el caso `y = 0` e `y = 1`, tratando de obtener los gráficos de la presentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, y_pred):\n",
    "    L = COMPLETAR\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0\n",
    "ys_pred = np.linspace(0,1,1000)\n",
    "plt.plot(ys_pred, cross_entropy_loss(y,ys_pred))\n",
    "plt.xlabel('y_pred, probabilidad predicha')\n",
    "plt.ylabel('Perdida')\n",
    "plt.title('y = 0')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escribir una función que, dado las etiquetas muchas instancias `y` y las predicciones `y_pred`, calcula la función de  costo *entropía cruzada* para todas las instancias. PISTA: hacer un `for` sobre las instancias y llamar a la función `cross_entropy_loss` que crearon antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_cost(y, y_pred):\n",
    "    ## Un sanity check\n",
    "    assert y_pred.size == y.size, 'Ojo que los vectores no tienen el mismo tamanio'\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.size)\n",
    "    y = y.reshape(y.size)\n",
    "    J = 0\n",
    "    for i in range(y_pred.size):\n",
    "        J += COMPLETAR\n",
    "    J /= y_pred.size\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Por si alguno/a quiere ver por que no usamos esta funcion de costo\n",
    "def MSE(y,y_pred):\n",
    "    '''Calcula Mean Squared Error'''\n",
    "    assert(len(y) == len(y_pred))\n",
    "    n = len(y)\n",
    "    return ((y - y_pred)**2).sum()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos del Challenger**\n",
    "\n",
    "Cargamos los datos usados en la presentación. Nosotros nos encargamos del preprocesamiento y de los gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Datasets/challenger_data.csv')\n",
    "dataset.dropna(inplace = True) # Tiramos los NaN (una sola fila)\n",
    "dataset['Temperature (C)'] = np.round((dataset['Temperature'] - 32)/1.8,2) # pasamos a celcius\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plot = sns.scatterplot(x = 'Date', y  = 'Temperature (C)', hue = 'Damage Incident', data = dataset, s = 100)\n",
    "for item in plot.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.drop([24], inplace = True)\n",
    "plt.figure(figsize = (8,4))\n",
    "plot = sns.scatterplot(x = 'Temperature (C)', y  = 'Damage Incident', hue = 'Damage Incident', data = dataset, s = 100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables para entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop([24])['Temperature (C)'].values\n",
    "y = dataset.drop([24])['Damage Incident'].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante reescalar los datos cuando trabajen con Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X.mean()\n",
    "X_std = X.std()\n",
    "X = (X - X_mean)/X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explorando la función de costo**\n",
    "\n",
    "El objetivo es lograr obtener el gráfico de la función de costo como hicimos la clase anterior. Para ellos, es importante que respondan: ¿cuántos parámetros tiene la función sigmoide/perceptrón?¿Qué tipo de gráfico quieren obtener?\n",
    "\n",
    "1. Crear un arreglo con valores para w0 y w1 (`w0s, w1s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0s = COMPLETAR\n",
    "w1s = COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recorrer los dos arreglos y calcular el costo para cada combinación de parámetros `w0, w1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "costos = []\n",
    "for w0 in COMPLETAR:\n",
    "    for w1 in COMPLETAR:\n",
    "        y_pred = COMPLETAR\n",
    "#         costos.append(MSE(y,y_pred))\n",
    "        costos.append(COMPLETAR)\n",
    "costos = np.array(costos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0s, W1s = np.meshgrid(w0s,w1s, indexing = 'ij')\n",
    "costos_matriz = costos.reshape(w0s.size, w1s.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_minimo = np.unravel_index(costos_matriz.argmin(), costos_matriz.shape)\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "plt.pcolormesh(W0s, W1s,costos_matriz)\n",
    "ax.contourf(W0s, W1s, costos_matriz)\n",
    "plt.colorbar()\n",
    "plt.scatter(W0s[idxs_minimo], W1s[idxs_minimo])\n",
    "plt.title('Costo en el minimo:' + str(costos_matriz[idxs_minimo]))\n",
    "plt.xlabel('W0')\n",
    "plt.ylabel('W1')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_encontrado = W0s[idxs_minimo]\n",
    "w1_encontrado = W1s[idxs_minimo]\n",
    "\n",
    "print('w0 encontrado:', w0_encontrado)\n",
    "print('w1 encontrado:', w1_encontrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(W0s, W1s,costos_matriz,linewidth=0.0, antialiased=False, cmap = 'plasma')\n",
    "# ax.view_init(0, 180)\n",
    "ax.set_xlabel('m')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('costo')\n",
    "plt.tight_layout()\n",
    "plt.colorbar(surf)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Graficar la función sigmoide para los parámetros obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plot = sns.scatterplot(x = 'Temperature (C)', y  = 'Damage Incident', hue = 'Damage Incident', data = dataset, s = 100)\n",
    "\n",
    "x_plot = np.linspace(-5,30,100)\n",
    "z = (x_plot - X_mean)/X_std\n",
    "plt.plot(x_plot, sigmoid_function(z,COMPLETAR,COMPLETAR))\n",
    "\n",
    "plt.axhline(0.5, ls = '--', c = 'r', label = 'probabilidad de 0.5')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron con Keras\n",
    "\n",
    "\n",
    "Keras es un entorno de desarrollo para Redes Neuronales de alto nivel. Esto quiere decir que es - o al menos trata de ser- más amigable que otros entornos de desarrollo, como por ejemplo TensorFlow. Sin embargo, está basado en TensorFlow, que es quien hace el \"trabajo pesado\". Una de las principales ventajas de Keras es que es rápido para hacer prototipos, hay muchas funciones de costo, optimizadores y tipo de neuronas implementadas, lo cual lo hacen muy versátil.\n",
    "\n",
    "Tal vez una desventaja sea que la documentación tiende a ser escueta. Pero por otro lado hay muchos ejemplos y tutoriales en internet que se pueden usar que están buenos.\n",
    "\n",
    "https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "Los pasos básicos a seguir con Keras son:\n",
    "1. Definimos un modelo: indicamos cantidad y tipos de neuronas.\n",
    "2. Compilamos el modelo: indicamos función de costo y optimizador.\n",
    "3. Entrenamos el modelo: cantidad de iteraciones y otros parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definimos el modelo. El tipo de modelo se llama `Sequential` y le agregamos una capa (`layer`) con una Neurona `Dense`, con una función de activación `'sigmoid'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compilamos el modelo llamando a `model.compile(...)`. Los argumentos más importantes son el optimizador `optimizer`, la pérdida `loss` y, si queremos, un métrica que evalúa durante el entrenamiento. **Importante**: solamente la evalúa, nada más.\n",
    "\n",
    "La forma en que pasamos los argumentos no es la única que hay, también se pueden crear *objetos* optimizadores y pasarles argumentos de forma más detallada. Mirar algunos ejemplos en la documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alan/anaconda3/envs/CursoPy/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.0, beta_2=0.0, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer= optimizer,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Entrenamos el modelo con `model.fit(...)`. Los argumentos son, en primer lugar, los features `X` y las etiquetas `y`, y la cantidad de iteraciones `epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-41aa0247fb3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.size, 1)\n",
    "history = model.fit(X, y, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá ya tenemos el modelo entrenado. Algunas funciones de Keras que están buenas:\n",
    "\n",
    "1. Obviamente, hacer predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: x=[-10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab45e7ea0aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/CursoPy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CursoPy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    658\u001b[0m                                      \u001b[0;34m'either a single '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                                      \u001b[0;34m'array or a list of arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                                      'You passed: x=' + str(x))\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0mall_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=[-10]"
     ]
    }
   ],
   "source": [
    "model.predict([-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa ese número que devuelve?\n",
    "\n",
    "2. Ver la cantidad de parámetros y capas del modelo. Tendrá más sentido cuando entrenemos redes más profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/CursoPy/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m                 \u001b[0;34m'Build the model first by calling build() '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0;34m'or calling fit() with some data. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ver la historia de entrenamiento del modelo. History es un objeto con muchas características, pero tiene guardado la pérdida para cada iteración y la métrica que le hayamos pedido que evalúe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Se pueden ver los pesos que obtuvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = model.get_weights()[0][0][0]\n",
    "w1 = model.get_weights()[1][0]\n",
    "print(w0,w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Y, como en todo modelo, podemos graficar el resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plot = sns.scatterplot(x = 'Temperature (C)', y  = 'Damage Incident', hue = 'Damage Incident', data = dataset, s = 100)\n",
    "\n",
    "x_plot = np.linspace(-5,30,100)\n",
    "z = (x_plot - X_mean)/X_std\n",
    "plt.plot(x_plot, model.predict(z))\n",
    "# plt.plot(x_plot, sigmoid_function(z,w0,w1))\n",
    "\n",
    "plt.axhline(0.5, ls = '--', c = 'r', label = 'probabilidad de 0.5')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón en 2D\n",
    "\n",
    "Seguimos con la mismas ideas que antes, pero ahora en vez de un feature hay dos. Vamos a generar un dataset sintético con unas funciones que ya vienen incorporadas en scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs, make_moons\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2,\n",
    "                  random_state=0)\n",
    "\n",
    "X, y = make_moons(n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X[:,0], y = X[:,1], hue = y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescalamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = (X[:,0] - X[:,0].COMPLETAR())/X[:,0].COMPLETAR()\n",
    "X[:,1] = (X[:,1] - X[:,1].COMPLETAR())/X[:,1].COMPLETAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X[:,0], y = X[:,1], hue = y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo a entrenar (perceptrón) y volvemos a mirar algunas de sus características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(COMPLETAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.0, beta_2=0.0, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=COMPLETAR,loss=COMPLETAR,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=COMPLETAR, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que se agregaron una keys, asociadas al set de validación. Grafiquemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos parámetros tiene ahora el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y graficamos las fronteras de decisión. ¿Notan que ya no es una frontera abrupta, sino que hay una zona de cambio?¿A qué se debe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "ax = sns.scatterplot(x = X[:,0], y = X[:,1], hue = y)\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, levels = 10, alpha=0.3, cmap = 'plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** volver a correr esta sección, pero reemplazando la función que genera los datos `make_blobs` por `make_moons`. ¿Qué problema ven en el resultado?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
