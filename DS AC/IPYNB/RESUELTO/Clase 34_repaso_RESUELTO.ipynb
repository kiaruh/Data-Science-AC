{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 5: Análisis de sentimiento en reviews de películas con keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar la biblioteca Keras de Deep Learning para realizar la misma clasificación que hicimos en el proyecto 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, carguemos las reviews para comenzar a procesarlas. En este caso no tenemos un archivo `.csv`, sino un directorio estructurado de la siguiente forma: \n",
    "```\n",
    "movie_reviews/\n",
    "  neg/\n",
    "  pos/\n",
    "```\n",
    "`sklearn` nos provee de la función `load_files` que permite recorrer este tipo de estructuras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "moviedir = r'./dataset/movie_reviews' \n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en la variable `movies` tendremos guardadas las reviews (`movies.data`) y su sentimiento (`movies.target`).\n",
    "Veamos cuantas reviews tenemos en total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 2000 reviews, con clases ['neg', 'pos'],\n"
     ]
    }
   ],
   "source": [
    "print(\"Tenemos {} reviews, con clases {},\".format(len(movie_reviews.data), movie_reviews.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando la estructura de los documentos, veamos como luce una muestra de `movies.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so cal\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.data[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora, con la propiedad `target` podemos ver la categoría asociada a esta review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso es un 0, es decir `neg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando en conjuntos de entrenamiento y de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el entrenamiento de los modelos probando distintos algoritmos para encontrar los mejores modelos, vamos a separar el conjunto de reviews en training y testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante destacar que el `fit` debe hacerse sobre el conjunto de `train` y no sobre el total, ya que `CountVectorizer` tiene en cuenta los términos existentes, por lo que si usamos el conjunto de test podrían aparecer nuevos términos que no contemplamos. Una vez que usamos el `fit` con el conjunto de entrenamiento podemos aplicar la transformación al conjunto de `test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensión de la matriz de términos\n",
    "Una vez vectorizados los documentos veamos qué forma tiene la matriz resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "max_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrená una red neuronal con Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importar la librería Sequential y layers\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tele/anaconda3/envs/acamica2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Constuir el modelo con 3 capas. \n",
    "# Qué función de activación eligirían para cada capa?\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(max_features,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tele/anaconda3/envs/acamica2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/10\n",
      "1280/1280 [==============================] - 1s 741us/step - loss: 0.7251 - acc: 0.5109 - val_loss: 0.6821 - val_acc: 0.5188\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.6415 - acc: 0.6477 - val_loss: 0.6339 - val_acc: 0.6594\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.5955 - acc: 0.6781 - val_loss: 0.6125 - val_acc: 0.6750\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 0s 148us/step - loss: 0.5766 - acc: 0.6891 - val_loss: 0.5834 - val_acc: 0.6938\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.4812 - acc: 0.7680 - val_loss: 0.6435 - val_acc: 0.6031\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.3947 - acc: 0.8563 - val_loss: 0.5990 - val_acc: 0.6562\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.3761 - acc: 0.8227 - val_loss: 0.5229 - val_acc: 0.7594\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 0s 128us/step - loss: 0.2608 - acc: 0.9437 - val_loss: 0.5329 - val_acc: 0.7156\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2189 - acc: 0.9484 - val_loss: 0.5388 - val_acc: 0.7281\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1995 - acc: 0.9531 - val_loss: 0.5227 - val_acc: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13816e4510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegir el batch_size\n",
    "model.fit(X_train,y_train,batch_size=512,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión \n",
    "Una forma de ver fácilmente el resultado de un clasificador es utilizando una matriz de confusión. A continuación\n",
    "se presenta una función para visualizar una matriz de confusión utilizando `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83       200\n",
      "           1       0.94      0.65      0.77       200\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.83      0.80      0.80       400\n",
      "weighted avg       0.83      0.80      0.80       400\n",
      "\n",
      "0.8025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_pred_vec = np_utils.to_categorical(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_vec[:,1]))\n",
    "print(accuracy_score(y_test, y_pred_vec[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Ejercicio: repetir modificando el número de muestras que se usa para entrenar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESAFÍO\n",
    "\n",
    "Aplicación de redes neuronales para el precio de las casas\n",
    "https://www.kaggle.com/diegosiebra/neural-network-model-for-house-prices-keras\n",
    "\n",
    "* Qué función de pérdida usa?\n",
    "* Qué función de activación se usa en la última capa? Por qué creen que hacen esto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
