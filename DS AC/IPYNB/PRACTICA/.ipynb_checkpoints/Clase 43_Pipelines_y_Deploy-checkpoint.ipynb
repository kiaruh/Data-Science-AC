{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenten si todavía no instalaron el cliente\n",
    "!pip install --upgrade watson-developer-cloud\n",
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el Dataset\n",
    "Importamos el dataset de review de películas que utilizamos para la entrega número 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "# Acá deben completar con la dirección donde tienen el dataset de películas que usamos para la entrega 5\n",
    "moviedir = r'./movie_reviews' \n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este dataset consisteia de un diccionario donde la key 'data' contenía el texto de la review, y la key 'target' tenía un 1 si fue ese review fué positivo y un 0 si fue negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armando el pipeline\n",
    "Primero, antes de definir nuestro workflow de trabajo, vamos a separar en Train y Test nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si, vamos a definir un workflow muy simple donde primero vectorizamos el texto, aplicamos una transofrmación tfidf y luego clasificamos con un SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ponemos estos dos pasos adentro de un único objeto, una instancia de un objeto Pipeline, al que llamamos 'pipeline'. Al igual que los otros modelos, también cuenta con las funciones fit y predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podríamos fitear y usar el modelo para predecir de manera local corriendo la siguiente linea.\n",
    "# Pero no es la idea, vamos a correrlo desde el servidor.\n",
    "pipeline2 = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])\n",
    "pipeline2.fit(X_train, y_train)\n",
    "pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentá la siguiente linea para hacer la instalación\n",
    "#!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar Watson Machine Learning API es necesario crear un servicio desde:\n",
    "https://console.bluemix.net/catalog/services/machine-learning.\n",
    "\n",
    "Una vez creado ir a la lista de la izquierda a `Service Credentials` y crear nuevas credenciales. \n",
    "\n",
    "Para ver las credenciales hay que tocar en `View Credentials`. \n",
    "De allí copiar los datos necesarios para completar el código de la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials={\n",
    "\"apikey\": \"R9z7zkQokmTXgt739iV9KBaKiwllDXMBXnSNVoYww3jI\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key 237e5578-f723-4589-b805-0bb8b1dddd13\",\n",
    "  \"iam_apikey_name\": \"Service credentials-1\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/ab2a28027ad8423ebd45c43a43570709::serviceid:ServiceId-346b358b-7c44-4886-a1b3-20ccb5144cc3\",\n",
    "  \"instance_id\": \"19b72f71-5441-4ae9-bcfc-dcd1a70bec14\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\"# Copien y peguen sus credenciales\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los datos del modelo a publicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Yo\", \n",
    "               client.repository.ModelMetaNames.NAME: \"Reviews classification nuevo\",\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_NAME: 'python',\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_VERSION: '3.6'}\n",
    "\n",
    "# Si quieren usar tensorflow, pueden especificar la versión como:\n",
    "#client.repository.DefinitionMetaNames.NAME: 'my_training_definition',\n",
    "#client.repository.DefinitionMetaNames.FRAMEWORK_NAME: 'tensorflow',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subimos el modelo a la nube con `client.repository.store_model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=pipeline, \n",
    "                                                meta_props=model_props, \n",
    "                                                training_data=X_train, \n",
    "                                                training_target=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el uid del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos el id con el cual nos vamos a referir al modelo\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_details = client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos cargar el modelo a partir de su `uid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = client.repository.load(published_model_uid)\n",
    "test_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"roc_auc score: \", roc_auc_score(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
