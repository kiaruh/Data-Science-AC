{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensambles\n",
    "\n",
    "A lo largo del notebook vamos a trabajar con el siguiente dataset:\n",
    "\n",
    "https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "que ya conocieron en el notebook clase_25_sesgo_y_varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Volvemos a cargas las librerías, importar el dataset y limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datasets/weatherAUS.csv\")\n",
    "# Columnas con muchos NaNs\n",
    "columnas_descartables = ['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "data = data.dropna()\n",
    "\n",
    "# Columnas con variables categoricas\n",
    "columnas_descartables = ['WindGustDir','WindDir9am','WindDir3pm','RainToday']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "\n",
    "# Variables correlacionadas\n",
    "data = data.drop(columns=['Temp3pm', 'Pressure9am'])\n",
    "\n",
    "# Mapeo\n",
    "data['RainTomorrow'] = data['RainTomorrow'].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos variables de entrenamiento. Elegir dos o más (si eligen dos no van a ver grandes mejoras en los modelos) y separamos las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_entrenamiento = ['MaxTemp', 'Humidity3pm']\n",
    "X = data[columnas_entrenamiento]\n",
    "# X = data.drop(columns = 'RainTomorrow')\n",
    "y = data.RainTomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y separamos entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bagging\n",
    "\n",
    "Recuerden que el objetivo de bagging es entrenar distintos modelos, donde cada uno vea distintas porciones del set de entrenamiento. Entonces, vamos a entrenar distintos árboles de decisión y mostrarles distintas porciones del set de datos. Lo vamos a hacer en un `for`.\n",
    "\n",
    "1. Crear una lista vacía donde guardaremos los modelos entrenados y elegir cuántos modelos entrenar (Empezar por algún valor entre 5 y 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_modelos = COMPLETAR\n",
    "N_modelos = COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Entrenar cada modelo y guardar cada modelo entrenado en una lista. Para hacer el split, usar la función `train_test_split`. ¿Sobre qué conjunto van a hacer el split?¿Hay que fijar el `random_state`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(COMPLETAR):\n",
    "    X_train_boostrap, _, y_train_boostrap, _ = train_test_split(COMPLETAR, COMPLETAR, test_size=0.5, stratify = COMPLETAR)\n",
    "    clf = DecisionTreeClassifier(max_depth = None) #Notar que lo dejamos overfitear\n",
    "    clf.fit(COMPLETAR, COMPLETAR)\n",
    "    lista_de_modelos.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluar el accuracy de cada modelo usando el conjunto de held_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, modelo in enumerate(COMPLETAR):\n",
    "    y_test_pred = modelo.predict(COMPLETAR)\n",
    "    print('Accuracy Modelo ', idx, ' es ', metrics.COMPLETAR(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parecen estar un poco overfitteados, que era lo que esperábamos.\n",
    "\n",
    "5. Evaluar el accuracy de todo el ensamble usando el conjunto de held_out. Vamos a hacerlo usando un promedio de las probabilidades que devuelven cada árbol. Si la probabilidad promedio es mayor a 0.5, clasificamos como positivo. Para ello:\n",
    "    1. Inicializar un arreglo de probabilidades del tamaño de la cantidad de instancias del conjunto de test en ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_test_pred = np.COMPLETAR(COMPLETAR.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Recorrer la lista de modelos y predecir las probabilidades. Mirar como es el `shape` de ese arreglo predicho. Elegir las probabilidades que correspondan a la clase positiva. Luego, sumarlas al vector que definieron antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelo in lista_de_modelos:\n",
    "    probs_test_pred_modelo = modelo.COMPLETAR(X_test)\n",
    "    print(probs_test_pred_modelo.shape)\n",
    "    # Cuando esten seguros de lo que quieran sumar, descomentar la linea de abajo y completar\n",
    "#     probs_test_pred +=probs_test_pred_modelo[COMPLETAR,COMPLETAR]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Dividir `probs_test_pred` por la cantidad de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_test_pred = probs_test_pred/COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Crear las clases predichas (0s y 1s) a partir de comparar la probabilidad predicha con la probabilidad umbral (0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = probs_test_pred>COMPLETAR\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y evaluar la exactitud de todo el ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Ensambe ', metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Explorar el `BagginClassfier` de scikit-learn y algunas de sus características. Usarlo para predecir sobre el train y test, y medir su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=COMPLETAR, bootstrap = COMPLETAR, bootstrap_features=COMPLETAR, n_estimators = 100, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_train, y_train_pred))\n",
    "print(metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Si usaron dos features, pueden graficar las fronteras de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "#Grafico Clasificador Sesgado\n",
    "ax = sns.scatterplot(X_test[::N].MaxTemp, X_test[::N].Humidity3pm, hue=y_test[::N], palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest\n",
    "\n",
    "Random Forest, además de aplicar Bagging, también selecciona features al azar, de esa manera descorrelaciona aún más los distintos modelos de árbol creados.\n",
    "\n",
    "1. Importar de scikit-learn el modelo `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.COMPLETAR import COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Investigar sus parámetros. En particular, `n_estimators`, `max_features` y `oob_score`. Luego, crear y entrenar un modelo en el conjunto de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=COMPLETAR, max_features=COMPLETAR, n_jobs=-1, oob_score = True, random_state = 42)\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluar su desempeño en el conjunto de train y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.COMPLETAR(COMPLETAR)\n",
    "y_test_pred = clf.COMPLETAR(COMPLETAR)\n",
    "print(metrics.COMPLETAR(COMPLETAR, COMPLETAR))\n",
    "print(metrics.COMPLETAR(COMPLETAR, COMPLETAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿Cuál es su `oob_score_`?¿Y que son `feature_importances_`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRER ESTA CELDA UNA VEZ QUE HAYAN ESTUDIADO QUE ES OOB_SCORE Y FEATURE_IMPORTANCES\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "columns = X_train.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "sns.barplot(columns[indices], importances[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Qué hay en la propiedad `estimators_`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Elegir uno de los `estimators` y evaluar su desempeño sobre train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = clf.estimators_[COMPLETAR]\n",
    "clf_tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf_tree.predict(X_train)\n",
    "y_test_pred = clf_tree.predict(X_test)\n",
    "print(metrics.accuracy_score(y_train, y_train_pred))\n",
    "print(metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Está overfiteado?¿Por qué la accuracy sobre el conjunto de train no es 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Hacer y graficar la curva de validación/complejidad para un modelo Random Forest en función del número de estimadores. No usamos CV porque puede llevar bastante tiempo. Si quieren, lo pueden probar después. Además, obtener su oob_score para graficar en la curva de complejidad (No se preocupen por los mensajes de warning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "oob_scores = []\n",
    "\n",
    "N_estimadores = [1,2,3,4,5,10,25,50,100,250,500,1000]\n",
    "for estimadores in COMPLETAR:\n",
    "    print(estimadores)\n",
    "    clf = RandomForestClassifier(n_estimators=COMPLETAR, n_jobs=-1, oob_score= True, random_state = 42)\n",
    "    clf.fit(COMPLETAR,COMPLETAR)\n",
    "    \n",
    "    y_train_pred = clf.predict(COMPLETAR)\n",
    "    y_test_pred = clf.predict(COMPLETAR)\n",
    "    \n",
    "    train_accuracy.append(COMPLETAR)\n",
    "    test_accuracy.append(COMPLETAR)\n",
    "    oob_scores.append(clf.COMPLETAR)\n",
    "    \n",
    "train_accuracy = np.array(train_accuracy)\n",
    "test_accuracy = np.array(test_accuracy)\n",
    "oob_scores = np.array(oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'Train')\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'Test')\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'OOB')\n",
    "plt.xlabel('Numero de estimadores')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.xlim(0,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Hacer y graficar la curva de aprendizaje para un modelo con 250 estimadores. Puede llevar bastante tiempo, no se preocupen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250, n_jobs=-1, oob_score= True, random_state = 42)\n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve(COMPLETAR, COMPLETAR, COMPLETAR, \n",
    "                                                         train_sizes = np.linspace(0.0001,1,10),\n",
    "                                                         scoring = 'accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(COMPLETAR, COMPLETAR.mean(axis = COMPLETAR), color = 'r')\n",
    "plt.plot(COMPLETAR, COMPLETAR.mean(axis = COMPLETAR), color = 'g')\n",
    "\n",
    "plt.fill_between(COMPLETAR, COMPLETAR,\n",
    "                     COMPLETAR, alpha=0.25,\n",
    "                     color=\"r\")\n",
    "plt.fill_between(COMPLETAR, COMPLETAR,\n",
    "                     COMPLETAR, alpha=0.25, color=\"g\")\n",
    "\n",
    "plt.ylim(0.5,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Si usaron dos features, pueden graficar las fronteras de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "clf = RandomForestClassifier(n_estimators=250).fit(X_train, y_train)\n",
    "\n",
    "#COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar**: ¿qué otras métricas utilizarían para evaluar estos modelos, dadas las características particulares de este modelo? Comparar con los casos *benchmark* que hicieron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Boosting\n",
    "\n",
    "El objetivo de boosting es generar un modelo fuerte a partir de entrenar sucesivamente modelos débiles y combinar sus resultados. La idea es que cada modelo debil que agrego se enfonque en las instancias que fueron clasificadas erroneamente hasta el momento. Empecemos por decidri sobre que fetures del dataset vamos a trabajar (si trabajan sobre 2, luego podrán visualizar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos sobre que coolumnas queremos trabajar\n",
    "columnas_entrenamiento = ['MaxTemp', 'Humidity3pm']\n",
    "X = COMPLETAR\n",
    "y = COMPLETAR\n",
    "\n",
    "# Separamos los datos en train y test (held-out) - Utilice un 30% del dataset como test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=COMPLETAR, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este tipo de ensamble se enfoca en mejorar el sesgo de los modelos individuales a partir de los cuales esta construido, por lo cual se suele usar modelos de alto sesgo y baja vatianza.\n",
    "\n",
    "1) Empiece por importar el clasificador AdaBoostClassifier y el modelos que usaremos como estimador debil, el DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Defina el modelo de manera que utilice 250 árboles de profundidad 2. Luego probaremos que sucede para mayores profundidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=COMPLETAR),algorithm='SAMME', n_estimators=250)\n",
    "# Entrenamos el modelo\n",
    "ada_clf.fit(COMPLETAR, COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calcule el error sobre el training set y sobre el test set. En base a estos resultados, les parece que este ensamble está inclinado hacia el sesgo o hacia la varianza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = COMPLETAR\n",
    "y_test_pred = COMPLETAR\n",
    "print('Accuracy sobre el test set: ',COMPLETAR)\n",
    "print('Accuracy sobre el train set: ',COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Veamos ahora como es la distribución de los pesos de cada arbol. Para esto vamos a graficar el número del arbol vs el peso que el algoritmo le está dando para la clsificación final. Ademas graficaremos también el accuracy de cada arbol sobre el training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede que el algoritmo termine antes de agregar todos los arboles\n",
    "# Tomamos entonces la cantidad de arboles que realmente tiene el ensamble\n",
    "numero_arboles = len(ada_clf)\n",
    "\n",
    "# En la variable estimator_weights_ esta el peso de cada arbol\n",
    "pesos = ada_clf.estimator_weights_[:numero_arboles]\n",
    "\n",
    "# Calculamos el accuracy DE CADA ARBOL en el ensamble. En estimator_errors_ esta el error que comete cada uno.\n",
    "errores_arboles = ada_clf.estimator_errors_[:numero_arboles]\n",
    "# Como puede calcular el accuracy de cada arbol a partir de saber el error que comete cada uno?\n",
    "accuracy_arboles = COMPLETAR\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(121)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' los pesos\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Peso')\n",
    "plt.xlabel('Número de árbol')\n",
    "plt.ylim((0, pesos.max() * 1.1))\n",
    "plt.xlim((-20, numero_arboles + 20))\n",
    "plt.subplot(122)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' el accuracy de cada arbol\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Accuracy en trainin set')\n",
    "plt.xlabel('Número de árbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Le parece relevante la contribución de todos los arboles? Como se relaciona el accuracy de cada arbol con el peso que le damos en la clasificación final? (Puede cambiar el rango de 'ylim' para ver en detalle la forma de las curvas).\n",
    "\n",
    "6) Veamos como cambia el error en el training set y en el test set a medida que agregamos arboles. Para esto vamos a utilizar un metodo llamado \"staged_predict\", que nos devuelve la predicción del ensamble en cada instancia en que fuimos agregandole un nuevo estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos listas vacias donde vamos a \"appendear\" (agregar) los valores\n",
    "accuracy_test = COMPLETAR\n",
    "accuracy_train = COMPLETAR\n",
    "\n",
    "# Calculamos el accuracy sobre el test set\n",
    "for prediccion_test in ada_clf.staged_predict(X_test):\n",
    "    accuracy_test.append(metrics.accuracy_score(prediccion_test,COMPLETAR))\n",
    "    \n",
    "# Calculamos el accuracy sobre el training set    \n",
    "for prediccion_train in ada_clf.staged_predict(X_train):  \n",
    "    accuracy_train.append(metrics.accuracy_score(prediccion_train,COMPLETAR))\n",
    "    \n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_test, label = 'Test')\n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_train, label = 'Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy en el test set')\n",
    "plt.xlabel('Número de árboles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Grafiquemos la frontera de desición del calsificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "ax = sns.scatterplot(X_test[::N].MaxTemp, X_test[::N].Humidity3pm, hue=y_test[::N], palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = ada_clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
