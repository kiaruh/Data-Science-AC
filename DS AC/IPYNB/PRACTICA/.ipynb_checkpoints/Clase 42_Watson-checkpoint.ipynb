{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-developer-cloud\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/a5/a89fc49bd82eb6ea569e45b43383c28cd51b5076f43010dcc3331c137ff5/watson-developer-cloud-2.10.1.tar.gz (248kB)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from watson-developer-cloud) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: python_dateutil>=2.5.3 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from watson-developer-cloud) (2.8.0)\n",
      "Collecting websocket-client==0.48.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/a1/72ef9aa26cfe1a75cee09fc1957e4723add9de098c15719416a1ee89386b/websocket_client-0.48.0-py2.py3-none-any.whl (198kB)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\datascienceac\\lib\\site-packages (from python_dateutil>=2.5.3->watson-developer-cloud) (1.12.0)\n",
      "Building wheels for collected packages: watson-developer-cloud\n",
      "  Building wheel for watson-developer-cloud (setup.py): started\n",
      "  Building wheel for watson-developer-cloud (setup.py): finished with status 'done'\n",
      "  Created wheel for watson-developer-cloud: filename=watson_developer_cloud-2.10.1-cp37-none-any.whl size=252819 sha256=60f01f7e133e44c4e8ba4796efd01e985bd0438f13377a6369c168ee8b977fd1\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\ea\\a7\\19\\fac0a408a586265eb374005308a7553d4494ab41b2fd88f5bc\n",
      "Successfully built watson-developer-cloud\n",
      "Installing collected packages: websocket-client, watson-developer-cloud\n",
      "Successfully installed watson-developer-cloud-2.10.1 websocket-client-0.48.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade watson-developer-cloud\n",
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando la API de watson\n",
    "En este paso van a precisar usar el api_key que se generan en la página de IBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Eso aparecía a en el notebook que se bajan de la página (ya no funciona):\n",
    "# from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "# from watson_developer_cloud.natural_language_understanding_v1 import Features, EmotionOptions, SentimentOptions\n",
    "\n",
    "# Esta es la nueva forma de hacerlo\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, CategoriesOptions, EmotionOptions, SentimentOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "authenticator = IAMAuthenticator('3x2RFmKUkalLtlgGJYOYewqbsWP-t4LcvvDfBgvLXL2l')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "   authenticator=authenticator,\n",
    "    version='2019-07-25'\n",
    ")\n",
    "natural_language_understanding.set_service_url('https://gateway.watsonplatform.net/natural-language-understanding/api')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from ibm_watson import MyService\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "authenticator = IAMAuthenticator('{apikey}')\n",
    "service = MyService(\n",
    "   authenticator=authenticator\n",
    ")\n",
    "service.set_service_url('{url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando a watson\n",
    "Exploremos el tipo de objeto que nos devuelve watson y como funciona para distintas frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto objetivo\n",
    "text = 'This is a very silly text, it drives me crazy when I read it.'\n",
    "\n",
    "# Importamos el modelo que vamos a usar y le avisamos que features queremo que devuelva\n",
    "# y en que lenguaje está el texto (esto es mejor que dejarlo adivinar)\n",
    "response = natural_language_understanding.analyze(text=text,features=Features(emotion=EmotionOptions(), sentiment=SentimentOptions()),language='en')\n",
    "resultado = response.result\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tomar solo alguno de los resultados, podemos acceder al diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado['sentiment']['document']['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora un texto en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto objetivo\n",
    "text = 'Este texto no tiene ningún objetivo, vive en la soledad que genera saber que su existencia no tiene un proposito determinado.'\n",
    "\n",
    "# Importamos el modelo que vamos a usar y le avisamos que features queremo que devuelva\n",
    "# y en que lenguaje está el texto (esto es mejor que dejarlo adivinar)\n",
    "response = natural_language_understanding.analyze(text=text,features=Features(emotion=EmotionOptions(), sentiment=SentimentOptions()),language='es')\n",
    "resultado = response.result\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset de Noticias Infobae de hoy\n",
    "Este es dataset se lo preparamos para que puedan explorar como funciona Watson en textos en español. Algunas de las funcionalidades se pierden (no reporta las emociones), pero si clasifica como positivo o negativo los cuerpos de texto. Noten que otra estrategia podría ser traducir el texto y leugo aplicarle el algoritmo de watson en ingles. Esta otra estrategia no siempre funciona bien, depende mucho de la calidad de la traducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = '2019_08_21.feather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero ver el sentimiento de los cuerpos de la noticia.\n",
    "noticias_hoy = pd.read_feather(nombre_archivo)\n",
    "noticias_hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuerpos = noticias_hoy.Texto\n",
    "titulos = noticias_hoy.Titulo\n",
    "print(len(cuerpos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el sentimiento para cada una de las noticias y agregarlo al dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cuerpos = []\n",
    "\n",
    "for este_texto in cuerpos:\n",
    "    \n",
    "    # Quitamos del texto este símbolo que indica final de parrafo\n",
    "    este_texto = este_texto.replace('\\n','')\n",
    "    \n",
    "    # Analisis sentimiento del cuerpo\n",
    "    # Le pedimos solo el sentimiento, y le avisamos que está en español\n",
    "    response = natural_language_understanding.analyze(text=este_texto,features=Features(sentiment=SentimentOptions()),language='es')\n",
    "    resultado = response.result\n",
    "    score_cuerpos.append(resultado['sentiment']['document']['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_cuerpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente agregamos la columna al dataset\n",
    "noticias_hoy['Sentimiento'] = score_cuerpos\n",
    "noticias_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos un poco los resultados. Veamos el promedio de sentimiento de todas las noticias (esto nos va a dar una idea del ánimo general del día). Luego busquemos la noticia mas positiva y la mas negativa, para ver si coincidimos con el criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_los_valores = noticias_hoy['Sentimiento']\n",
    "animo_general = np.mean(todos_los_valores)\n",
    "print(animo_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_positiva = noticias_hoy.loc[noticias_hoy['Sentimiento'].idxmax()]\n",
    "print(noticia_positiva.Titulo)\n",
    "print(noticia_positiva.Sentimiento)\n",
    "#print(noticia_positiva.Subtitulo)\n",
    "print(noticia_positiva.Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_negativa = noticias_hoy.loc[noticias_hoy['Sentimiento'].idxmin()]\n",
    "print(noticia_negativa.Titulo)\n",
    "print(noticia_negativa.Sentimiento)\n",
    "#print(noticia_negativa.Subtitulo)\n",
    "#print(noticia_negativa.Texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra:\n",
    "\n",
    "Explorar otros recursos disponibles en IBM cloud: https://cloud.ibm.com/catalog?search=label%3Alite\n",
    "\n",
    "A continuación les dejamos un ejemplo de un modelo entrenado para clasificar comida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import VisualRecognitionV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "authenticator = IAMAuthenticator('eKmTwbs_ByrOzP4eTDY3dc0VR502vK5zCIxVAp7-sQd5')\n",
    "visual_recognition = VisualRecognitionV3(\n",
    "    version='2018-03-19',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "visual_recognition.set_service_url('https://gateway.watsonplatform.net/visual-recognition/api')\n",
    "\n",
    "url = 'https://ibm.biz/Bd2NPs'\n",
    "classifier_ids = [\"food\"]\n",
    "\n",
    "classes_result = visual_recognition.classify(url=url, classifier_ids=classifier_ids).get_result()\n",
    "print(json.dumps(classes_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import VisualRecognitionV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "\n",
    "url = 'https://watson-developer-cloud.github.io/doc-tutorial-downloads/visual-recognition/640px-IBM_VGA_90X8941_on_PS55.jpg'\n",
    "classifier_ids = [\"food\"]\n",
    "\n",
    "classes_result = visual_recognition.classify(url=url, classifier_ids=classifier_ids).get_result()\n",
    "print(json.dumps(classes_result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
