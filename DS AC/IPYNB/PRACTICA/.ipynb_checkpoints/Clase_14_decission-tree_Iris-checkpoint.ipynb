{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión con Scikit-Learn\n",
    "\n",
    "Vamos a trabajar con un dataset que es muy conocido, el iris dataset. Acá pueden encontrar más información al respecto:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "Se puede importar desde seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y visualizamos de una manera conveniente. ¡Este gráfico es un clásico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue=\"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar**: ¿Son separables las especies?¿Cuáles serán más fáciles de separar?¿Con qué atributos?\n",
    "\n",
    "### DecisionTreeClassifier\n",
    "\n",
    "Vamos a entrenar un árbol de decisión usando Scikit-Learn. Para ello:\n",
    "\n",
    "\n",
    "**Ejercicio 1**: importar un DecisionTreeClassifier de Scikit-Learn. ¿Cuáles son sus parámetros? En particular, investigar \"criterion\" y \"max_depth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**: crear un DecisionTreeClassifier con max_depth = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**: separar del dataframes iris los features y las etiquetas. Llamar \"X\" a los features e \"y\" a las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4**: entrenar el DecisionTreeClassifier que crearon con los datos \"X\" y las etiquetas \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PISTA: FIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5**: explorar algunas características del modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.classes_)\n",
    "# print(clf.n_classes_)\n",
    "# print(clf.max_features_)\n",
    "# print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacé un gráfico de barras para visualizar feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6**: predecir con el modelo las etiquetas de todas las instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PISTA: predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos etiquetas predichas y valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fila = 100\n",
    "print('La prediccion es', y_pred[fila],'. La etiqueta verdadera es', y[fila])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7**: ¿Cuán bien predijo?¿Cómo lo evaluarían? Usar, de scikit-learn, accuracy_score para evaluar la performance del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8**: ¿Qué ocurre con el desempeño a medida que aumentamos max_depth? Volver a correr todas las celdas, pero inicializando el DecisionTreeClassifier con valores más altos de max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar**: ¿hay algo que les haga ruido de la metodología empleada hasta ahora?¿Qué ocurre si hacemos max_depth suficientemente grande?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: fronteras de decisión\n",
    "\n",
    "Vamos a graficar las fronteras de decisión que aprende el algoritmo. Para ello, entrenamos un clasificador, pero solamente con dos atributos, petal_width y petal_lenght.\n",
    "\n",
    "No se preocupen por entender código a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Creamos el clasificador\n",
    "clf = DecisionTreeClassifier(max_depth = 3)\n",
    "\n",
    "# # Modificamos un poco los datos para poder graficar\n",
    "y_train = y.map({'setosa': 0,'versicolor': 1, 'virginica': 2})\n",
    "\n",
    "# Entrenamos\n",
    "clf.fit(X[['petal_width', 'petal_length']], y_train)\n",
    "\n",
    "# Graficamos los datos y las fronteras creadas\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(X.petal_width, X.petal_length, hue=y, palette='Set2')\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para probar**:¿Cómo se modifican las fronteras a medida que cambian el max_depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategias para elegir los mejores hiperparámetros\n",
    "\n",
    "\n",
    "El hiperparámetro más importantes de los árboles binarios de clasificación es la profundidad. ¿Cuál se imaginan que es el problema de elegir una profunidad máxima infinita (Es decir, None)? ¿Y de elegir profundidad máxima cero? \n",
    "\n",
    "Queremos ver qué cambia en las fronteras de decisión a medida que aumento la profundidad del árbol. Para ello,\n",
    "\n",
    "**1.** Entrenar un árbol de decisión con profundidad máxima uno y graficar su frontera de decisión. Luego, ir variando en uno la profundidad máxima del árbol para poder determinar qué pasa con esas fronteras.\n",
    "\n",
    "**2.** ¿Qué pasa con las fronteras de decisión en el caso de profundidad infinita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 100\n",
    "clf = DecisionTreeClassifier(max_depth = max_depth,random_state=0)\n",
    "y_train = y.map({'setosa': 0,'versicolor': 1, 'virginica': 2})\n",
    "clf.fit(X[['petal_width', 'petal_length']], y_train)\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(X.petal_width, X.petal_length, hue=y, palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificá tu hipótesis graficando árboles de distinta profundidad. ¿Qué pasa si graficás un árbol de profundidad infinita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz \n",
    "\n",
    "\n",
    "max_depth = None\n",
    "clf = DecisionTreeClassifier(max_depth = max_depth)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None,class_names=clf.classes_,feature_names=X.columns,filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** ¿Qué pasa con el *score* del modelo a medida que aumentamos la profundidad del árbol? ¿Pensás que refleja la *performance* real del modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "accuracy = []\n",
    "for max_depth in range(1,15):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_depth)\n",
    "    clf.fit(X, y)\n",
    "    y_pred=clf.predict(X)\n",
    "    accuracy.append(accuracy_score(y,y_pred,normalize=True))\n",
    "    \n",
    "    \n",
    "plt.plot(range(1,15), accuracy,'o')\n",
    "plt.title(\"Score en función de la profundidad del árbol\")\n",
    "plt.xlim([0,15]);plt.xlabel('Profundidad')\n",
    "plt.ylim([0.6,1.05]);plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARA PENSAR**: ¿Qué alternativas se te ocurren para tener una evaluación más realista del modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de validación\n",
    "\n",
    "La idea es separar los datos disponibles en un conjunto de \"entrenamiento\", que utilizaremos para entrenar el modelo de ML, y otro de \"validación\"(o \"test\") que utilizaremos para testearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar las siguientes lineas y completar las funciones correspondientes. Vas a tener que googlear.\n",
    "# Te recomendamos utilizar un 30% de los datos para validar el modelo. \n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(###Completar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrená el modelo con los datos de entrenamiento con max_depth = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculá el accuracy con los datos de validación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a investigar cómo se comporta el score del modelo sobre los datos de entrenamiento y sobre los datos de validación a medida que aumentamos la profundidad máxima del árbol (de 0 a 15). Para eso, sólamente tenés que correr las próximas lineas. \n",
    "\n",
    "¿Qué interpretación le das a cada una de las curvas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "accuracy = []\n",
    "accuracy_test = []\n",
    "for max_depth in range(1,15):\n",
    "    clf = DecisionTreeClassifier(max_depth = max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_train)\n",
    "    accuracy.append(accuracy_score(y_train,y_pred,normalize=True))\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_test.append(accuracy_score(y_test,y_test_pred,normalize=True))\n",
    "\n",
    "    \n",
    "plt.plot(range(1,15), accuracy, label='Training')\n",
    "plt.plot(range(1,15), accuracy_test, label='Testing')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curvas de complejidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
