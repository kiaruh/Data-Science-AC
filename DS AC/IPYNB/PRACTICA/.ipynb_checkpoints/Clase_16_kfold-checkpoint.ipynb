{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación del IRIS dataset con KNN. \n",
    "Vamos a entrenar dos algoritmos de clasificación usando el IRIS Dataset. La idea es que después de terminar el ejercicio comparen la performance de los árboles de decisión y KNN, y determinen cuál es, a su criterio, el que mejor funciona para clasificar estos datos. \n",
    "**Recuerden que las conclusiones que saquemos de este procedimiento son propias del problema.** ¡Manos a la obra! \n",
    "\n",
    "\n",
    "## A. Cargar el dataset\n",
    "1. Importar numpy pandas, matplotlib y seaborn. \n",
    "2. Cargar el iris dataset. \n",
    "3. Separar el dataset en datos (X) y etiquetas (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3b7ab25cf374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Separar el dataset en conjuntos de entrenamiento (X_dev, y_dev) y de testeo (X_held,y_held) usando la función **train_test_split** de scikit-learn [recordar importarla primero!]. Usar el 30% de las muestras para el held-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Preprocessing. \n",
    "Como vimos las veces que utilizamos este dataset, las distintas variables no están normalizadas. Para que KNN funcione bien, es conveniente que lo estén (¿Por qué?). Entonces, vamos a utilizar el StandardScaler para que estas variables sean comparables. \n",
    "\n",
    "0. Chequeá cuál es el mean y el std de X_dev y X_held. \n",
    "1. Importá el StandardScaler. \n",
    "2. Cargar el StandardScaler.\n",
    "3. Fittearlo con los datos de entrenamiento X_dev (¿Por qué no con y_dev?¿Por qué no con X_held? Si no sabés estas preguntas, seguí adelante y replanteatelas al final del ejercicio.)\n",
    "4. Transformá las variables X_dev e X_held con el StandatdScaler que entrenaste (¿Por qué no y_train e y_test?Si no sabés estas preguntas, seguí adelante y replanteatelas al final del ejercicio.)\n",
    "5. Chequeá cuál es el mean y el std de las X_dev y X_held transformadas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. KNN \n",
    "1. Importá el modelo de KNN de sklearn usando la siguiente linea: *from sklearn.neighbors import KNeighborsClassifier* \n",
    "2. Cuando cargamos el algoritmo, tenemos que indicarle los hiperparámetros que queremos utilizar. La distancia, por default, es la euclideana. Cargá el modelo utilizando 5 vecinos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fiteá el modelo utilizando los datos de entrenamiento escaleados. \n",
    "4. Calculá el Accuracy DE DEV [importar funciones necesarias]\n",
    "5. Calculá el Accuracy DE HELD-OUT.\n",
    "6. ¿Conclusiones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Para poder determinar el hiperparámetro K, es útil trazar la curva de complejidad. Corré las lineas a continuación e interpretá la curva. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "####\n",
    "#### PONERLE ESTOS NOMBRE A LAS VARIABLES\n",
    "# clf = modelo fiteado\n",
    "# X_dev_scal, X_held_scal = datos escaleados\n",
    "\n",
    "\n",
    "####\n",
    "ACC_dev = []\n",
    "ACC_held = []\n",
    "vecinos = [1,3,5,10,15,20,30,40,50,60,70,80,90,100]\n",
    "for n in vecinos:\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    clf.fit(X_dev_scal,y_dev)\n",
    "    y_dev_pred = clf.predict(X_dev_scal)\n",
    "    dev_acc = accuracy_score(y_dev, y_dev_pred)\n",
    "    ACC_dev.append(dev_acc)\n",
    "    y_held_pred = clf.predict(X_held_scal)\n",
    "    held_acc = accuracy_score(y_held, y_held_pred)\n",
    "    ACC_held.append(held_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vecinos,ACC_dev,'o-',label='dev' )\n",
    "plt.plot(vecinos,ACC_held,'o-',label='held')\n",
    "plt.xlabel('Numero de vecinos')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegí un intervalo donde te parece que es razonable buscar el K y volvé a graficar. ¿Cuál K usarías? [NOTA BIEN EN QUÉ ESCALA ESTA EL EJE \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = ???\n",
    "\n",
    "plt.plot(vecinos[:x],ACC_dev[:x],'o-',label='dev' )\n",
    "plt.plot(vecinos[:x],ACC_held[:x],'o-',label='held')\n",
    "plt.xlabel('Numero de vecinos')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Ahora trabajemos los nuevos conceptos sobre lo aprendido. Para eso, vamos a implementar K-fold cross validation para el caso de KNN aplicado al Dataset de IRIS.\n",
    "\n",
    "Les recomendamos seguir las instrucciones al pie de la letra antes de desesperar. \n",
    "\n",
    "Antes de empezar, corré hasta acá el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos los folds en los que queremos entrenar y testear.\n",
    "# Se te ocurre algún caso donde shuffle debe ser False? (si no se te ocurre, dejá para el final esta pregunta)\n",
    "kf = KFold(n_splits=10,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver qué hace la función `KFold`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completá la funcion para que esto funcione\n",
    "# PASO 1) Llamá 'X' a la variable que creés que hay que separar en distintos folds\n",
    "# PASO 2) Ejecutá  esta celda. Investigá qué pasa. \n",
    "X =\n",
    "y = \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\" \\n \\n \\n \\n TRAIN:\", train_index, \" \\n \\n TEST:\", test_index)\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que sabemos como funciona el k-fold podemos utilizarlo para evaluar la performance del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completá con las siguientes instrucciones:\n",
    "\n",
    "# 1- Separar en conjunto train y test, usando como ejemplo la celda de arriba\n",
    "# 2- Entrenar el StdScaler con los datos de entrenamiento\n",
    "# 3- Re-escalar tus datos (y no etiquetas) de entrenamiento y test \n",
    "# 4- Llamar al algoritmo de KNN de sklearn. Elegir el número de vecinos que creas conveniente, según analizaste clases anteriores\n",
    "# 5- Fiteá el modelo con los datos de entrenamiento. \n",
    "# 6- Realizá predicciones para los conjuntos de entrenamiento y test (ojo la escala!)\n",
    "# 5- Calculá el accuracy_score del conjunto de entrenamiento y guardala en la variable 'train_acc'\n",
    "# 6- Calculá el accuracy_score del conjunto de test y guardala en la variable 'test_acc'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot del Accuracy de los conjuntos de entrenamiento y validación. \n",
    "\n",
    "Qué valor de accuracy reportarías?\n",
    "Qué nos dice la varianza en cada caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot del Accuracy de los conjuntos de entrenamiento y validación. \n",
    "\n",
    "## Qué valor de accuracy reportarías?\n",
    "## Qué nos dice la varianza en cada caso?\n",
    "\n",
    "plt.plot([1]*len(TRAIN_ACC),TRAIN_ACC,'o',label='train')\n",
    "plt.plot([2]*len(TEST_ACC),TEST_ACC,'o',label='test')\n",
    "plt.ylim(0.7,1.1)\n",
    "plt.boxplot([TRAIN_ACC,TEST_ACC]);\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En la Celda que sigue, vamos a realizar la curva de complejidad. Esta vez vamos a utilizar validación cruzada. \n",
    "Vamos a reportar el  valor medio del accuracy y su varianza. \n",
    "\n",
    "No tenés que hacer nada más que ejecutar la celda e intentar entender qué significa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### En la Celda que sigue, vamos a realizar la curva de complejidad. Esta vez vamos a utilizar validación cruzada. \n",
    "### Vamos a reportar el  valor medio del accuracy y su varianza. \n",
    "### No tenés que hacer nada más que ejecutar la celda e intentar entender qué significa. \n",
    "\n",
    "vecinos = [1,3,5,10,15,20,30,40,50,60,70,80,90]\n",
    "\n",
    "X = pd.DataFrame(X_dev)\n",
    "y = pd.DataFrame(y_dev)\n",
    "\n",
    "X=X.reset_index()\n",
    "y=y.reset_index()\n",
    "\n",
    "\n",
    "TEST_ACC,TRAIN_ACC=[],[]\n",
    "TEST_ACC_var,TRAIN_ACC_var=[],[]\n",
    "\n",
    "for n in vecinos:\n",
    "    aux_TEST_ACC,aux_TRAIN_ACC=[],[]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train);\n",
    "        X_train_scal = scaler.transform(X_train)  \n",
    "        X_test_scal = scaler.transform(X_test)  \n",
    "        clf = KNeighborsClassifier(n_neighbors=n)\n",
    "        clf.fit(X_train_scal,y_train.species)\n",
    "        y_train_pred = clf.predict(X_train_scal)\n",
    "        train_acc = accuracy_score(y_train.species, y_train_pred)\n",
    "        y_test_pred = clf.predict(X_test_scal)\n",
    "        test_acc = accuracy_score(y_test.species, y_test_pred)\n",
    "        aux_TEST_ACC.append(test_acc)\n",
    "        aux_TRAIN_ACC.append(train_acc)\n",
    "    \n",
    "    TEST_ACC.append(np.mean(aux_TEST_ACC))\n",
    "    TRAIN_ACC.append(np.mean(aux_TRAIN_ACC))\n",
    "    TEST_ACC_var.append(np.std(aux_TEST_ACC))\n",
    "    TRAIN_ACC_var.append(np.std(aux_TRAIN_ACC))\n",
    "\n",
    "plt.errorbar(x=vecinos,y=TEST_ACC,yerr=TEST_ACC_var,fmt='o-',label='test',alpha=0.7)\n",
    "\n",
    "plt.errorbar(x=vecinos,y=TRAIN_ACC,yerr=TRAIN_ACC_var,fmt='o-',label='train',alpha=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESAFÍO 1: ¿Qué paso de la cross-validación creen que no está implementado en el orden adecuado? ¿Cómo lo resolverías?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESAFÍO 2: Trazar la curva de complejidad usando cross-validation para árboles de decisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: \n",
    "\n",
    "Investigar qué características tienen\n",
    "* Leave-one-out cross validation \n",
    "* Suffle-split cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
