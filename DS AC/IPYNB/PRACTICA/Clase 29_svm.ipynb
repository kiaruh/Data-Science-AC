{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: SVM: Continuamos con las predicciones sobre datos de cáncer de mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Continuamos con la tarea encarada en otros labs de clasificación de predecir el diagnóstico de cáncer de mama a partir de las características de las células.\n",
    "\n",
    "\n",
    "* class_t es la variable target\n",
    "\n",
    "* el resto son variables con valores normalizados de 1 a 10\n",
    "\n",
    "\n",
    "[Aquí](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names) pueden encontrar más información sobre el dataset.\n",
    "\n",
    "**Nota:** se eliminaron del dataset original 16 casos con valores perdidos en algunos campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importamos los datos\n",
    "\n",
    "df = pd.read_csv('breast-cancer.csv', header = None)\n",
    "df.columns = ['ID', 'clump_Thickness', 'unif_cell_size', 'unif_cell_shape', 'adhesion', 'epith_cell_Size', 'bare_nuclei',\n",
    "              'bland_chromatin ','norm_nucleoli', 'mitoses', 'class_t']\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow de clasificación\n",
    "\n",
    "La idea es implementar el modelo sobre el dataset utilizando cross validation para hacer una búsqueda sobre los hiperparámetros. \n",
    "Para tener tanto una estimación de los hiperparámetros óptimos como una idea de la performance sobre el modelo sobre datos nuevos vamos a completar el siguiente workflow:\n",
    "\n",
    "<img src='worflowtt.png'></img>\n",
    "\n",
    "Realicen el workflow teniendo en cuenta las siguientes condiciones:\n",
    "\n",
    "1) Hacer un split train/test incial dejando 75% y 25% de los datos respectivamente.\n",
    "\n",
    "2) A la hora de explorar los hiperparámetros probar los valores de C = [1, 10, 100, 1000] y probar con los kernels de tipo radial y lineal.\n",
    "\n",
    "\n",
    "Normalizar los features. ¿Por qué?  ¿Hace falta normalizar en SVM ?\n",
    "\n",
    "3) Utilizar 5 folds para el calcular el score de cross validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['clump_Thickness', 'unif_cell_size', 'unif_cell_shape', 'adhesion', 'epith_cell_Size', 'bare_nuclei',\n",
    "              'bland_chromatin ','norm_nucleoli', 'mitoses']]\n",
    "y = df['class_t']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
